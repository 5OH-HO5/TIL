# 크롤링이란

**web** 상에 존재하는 **contents** 를 수집하는 작업

### BeautifulSoup

```
from bs4 import BeautifulSoup
import requests
```

두 전처리기를 통해 크롤링을 준비 해준다.

#### 첫번째로 원하는 페이지의 url을 가져와준다.

```
url = "데이터 수집을 위한 웹 페이지의 url"
responce = requests.get(url)
```

url을 가져와 **import** 한 **requests** 클레스를 사용해 해당 url을 가져온다

requests.get을 통해 url의 데이터를 가져온다 **url**에 접속을 잘했다면 `RESPONSE[200]` 라는 결과 값을 가져온다.

```
soup = BeauifulSoup(responce.text , "html.parser")
```

requests 메서드를 통해 가져온 url 데이터를 **BeautifulSoup** 에 설정 해준다.

#### 두번째로 원하는 content의 tag값을 가져온다

1. ```
   soup.find(가져오고싶은 content의 tag값)
   ```

   만약 tag의 속성값을 통해 **content** 를 가져오고 싶다면 **딕션어리** 타입으로

   `("table" , {"class": "table_develop3"})`

   **table** 태그 형식에 **class** 이름이 **table_develop3** 이다.

2. ```
   soup.select_one(원하는 id값)
   ```

   **매개변수**로 들어갈 값은

   [![img](https://github.com/Junnnnnnnnnnn/TIL/raw/master/python/%ED%81%AC%EB%A1%A4%EB%A7%81/BeautifulSoup_%EC%82%AC%EC%9A%A9%EB%B2%95.assets/selecter.png)](https://github.com/Junnnnnnnnnnn/TIL/blob/master/python/크롤링/BeautifulSoup_사용법.assets/selecter.png)

   를 통해 **카피**하고 적용시켜 준다

   ```
   daller = soup.select_one("#exchangeList > li.on > a.head.usd > div > span.value")
   ```



> **SELECT_ONE**

1. 자식 문장으로 내려가기 '>'기호

   ex)  ol 태그 안에 li 태그가기

   ​		ol > li

2. class가 pizza인 ul태그 안에 ID가 good인 li태그 선택

   ex) ol.pizza > li#good

> **select**

select = element list 그 태그에 부합하는 모든 것 가져옴

select_one = 그 태그에 해당하는 내용만 가져옴

